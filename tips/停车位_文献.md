# 停车位检测

大概总结一下之前的各种尝试。

## 1. SPFCN

### 1.1 模型简述

[arxiv](https://arxiv.org/abs/2203.11337) | [github](https://github.com/tjiiv-cprg/SPFCN-ParkingSlotDetection)

模型总体结构为单独一个Hourglass模块，很简易，输出为宽高与输入图一致的三通道图，输入宽高为224x224时总算力不到1GMACs。但是在输出层含义上论文和官方github代码有出入：论文中三通道输出分别为角点、进入线、两侧线的热力图；而代码实现则变为角点热力图、两侧线的方向角的sin和cos值。

另外，名称中的SP表示在最后筛选并去除多余通道(Select & Prune)，这个操作或许在减少纸面计算量上有一点用，但是会导致最终得到的模型的各层通道数稀碎，减少的这部分计算量在CPU计算的情况下或许用处比较大，但是在后端为C7x+MMA这种HWA的情况下只能说感觉没有什么用。

### 1.2 问题与尝试

1. 原模型带SE-Block，SE-Block中对每个通道做乘法这个操作tidl后端不支持。考虑到模型特别小，就尝试用ncnn转化完，在板子上绕过tidl用A72跑模型，结果是即使模型已经如此小，但是用浮点模型还是跑出了接近一秒一帧的效果。至此基本确定板子上绕过tidl跑深度学习网络基本是不可能的。
2. 前面提到过论文和代码实现有出入，最后采取了实际实现的方法；经过一些小修改后模型能用tidl转了，结果主要问题出现在了int8量化上。当时8.+的sdk还没出，7.1的sdk不支持输出float32，又没给TensorScale，而正确率和出来的后两个通道数值强相关，看着打印的out.max()得到的141的值一脸懵，只能放弃这种做法。
3. 现在sdk8.+虽然支持输出浮点，且经测试精度损失不大，但看到SPFCN代码实现中复杂且很多人为设定的特别阈值后，对这种做法的可行性还是比较怀疑。

## 2. 一系列DNN

TODO(很多记不清楚了)但是大概是网络计算量要求过高，或者用了较为复杂的结构，输出格式不靠谱，或者压根实现的代码就没开源。

另外，那个韩国公司做的停车位检测，从视频来看应该是基于角点的检测，先检测出角点再在后处理中进行车位匹配。

## 3. ti-psd

### 3.1 模型简述

ti的目标检测demo里面给了一个停车位检测的模型bin文件，通过解析模型bin文件，以及看demo的postproc后处理代码反推出了他们用的模型，主体基于ssd；分类分支不变，回归分支在原基础(dCx, dCy, w, h)上加入(dP1x, dP1y, dP2x, dP2y, dP3x, dP3y, dP4x, dP4y)，回归得到车位的四个角点对于中心点的偏移量。关键点偏移量的损失全部采用SmoothL1Loss。网络大小和算力符合要求，在10GMACs以内。

(注：variance为0.2, 0.2, 0.1, 0.1, 0.05, ..., 从demo后处理里抄的)

### 3.2 问题与尝试

1. 最开始尝试像demo里面一样用单视图做检测，跑出来的模型勉强能用，点的位置有些许偏移。因为后处理中的nms仍然基于原来的外接框处理，所以如果用iou_threshold的以往经验值，会导致筛掉有用的框，需加大iou阈值。
2. 再尝试在环视拼接图中做检测，新的问题主要出现在四个点的顺序：标注格式为点1点4为入口点，4个点呈逆时针顺序。左边和右边车位的各点的相对位置不同，模型收敛速度较慢，故采取切半的方式，左边部分旋转180°后就和右边一致了。这种方式得到的模型训练集上效果满足要求，但是上车测试发现误检测率较高。

## 4. YOLO-based

### 4.1 模型简述

模型主体基于yolov5，输出回归部分由(dCx, dCy, w, h)变为(dCx, dCy, cosθ1, sinθ1, cosθ2, sinθ2, leng)。点部分后处理不变，角度为y=2x-1, 长度为y=2x*anc。回归损失全部采用SmoothL1Loss(网络sigmoid层后的SML1，各损失间的影响由权重再调节)

### 4.2问题

1. 训练上开始的模型泛化性不够好，对稍微偏一些的角度预测效果比较差，加入fliplr, flipud, warp_affine(translate)等数据增强后有改善。
2. 部署上因为后处理部分tidl并不支持，先去掉transpose和reshape等不单独支持的层，然而后面的split+mul+add层转换也出了问题(tidl上eltwise层在一边为固定值时似乎无法正确转换)，再退一步想让输出整体x2，看了ti-e2e上的一些说明后决定用batchnorm层近似这种效果；转换是成功了，就是无法输出为float32，int8的输出难以解析，就去掉了detectoutput层，让网络在sigmoid层后直接输出float32。后处理大概要在A72上面跑了。
3. 视频测试结果发现检测结果中两个入口点存在一定抖动情况，推测和这种中心点+角度+长度的形式有一定关系，改善抖动的方法可能是直接检测两个入口点？(如果检测入口点，同样的问题：点的顺序？)